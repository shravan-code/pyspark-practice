Below is a **clear, interview-ready explanation of all 30 Apache Spark concepts**, ordered logically from **architecture Рєњ planning Рєњ execution Рєњ memory**. IРђЎll keep it **conceptual + technical**, exactly how interviewers expect.

![Image](https://spark.apache.org/docs/latest/img/cluster-overview.png)

![Image](https://miro.medium.com/0%2A7325wPK9E8db2_DB)

![Image](https://i.sstatic.net/1y2zm.png)

![Image](https://docs.aws.amazon.com/images/prescriptive-guidance/latest/tuning-aws-glue-for-apache-spark/images/architecture-driver-cluster-worker.png)

---

## 1№ИЈРЃБ DAG (Directed Acyclic Graph)

A **DAG** is SparkРђЎs internal execution graph.

* **Directed** Рєњ data flows in one direction
* **Acyclic** Рєњ no loops
* Nodes = transformations
* Edges = data dependencies

Spark builds a DAG from transformations **before execution** to optimize computation.

---

## 2№ИЈРЃБ Cluster

A **cluster** is a group of machines (nodes) working together.

* One **driver node**
* Multiple **worker nodes**
* Used to distribute data and computation

---

## 3№ИЈРЃБ Cluster Manager / Resource Manager

The **Cluster Manager** allocates resources (CPU, memory).
Examples:

* Standalone
* YARN
* Kubernetes
* Mesos

It **does NOT run tasks**, only assigns resources.

---

## 4№ИЈРЃБ Application Master (AM)

(Primarily in YARN mode)

* Manages a **single Spark application**
* Negotiates resources with YARN
* Monitors executor lifecycle

­ЪЉЅ Exists **per application**

---

## 5№ИЈРЃБ Application Driver

The **driver** is the brain of a Spark application.
Responsibilities:

* Converts code Рєњ logical plan Рєњ physical plan
* Creates DAGs, jobs, stages, tasks
* Communicates with cluster manager
* Collects results

---

## 6№ИЈРЃБ PySpark Driver

Same as Spark driver, but:

* Written in **Python**
* Talks to JVM driver via **Py4J**
* Python code Рєњ JVM Spark execution

---

## 7№ИЈРЃБ Executors

Executors are **worker JVM processes**.
They:

* Execute tasks
* Store data (cache)
* Perform shuffles

­ЪЉЅ One executor = multiple task slots

---

## 8№ИЈРЃБ Client Mode

* Driver runs on **client machine**
* Executors run on cluster
* Client must stay alive

­ЪЊї Good for development, **bad for production**

---

## 9№ИЈРЃБ Cluster Mode

* Driver runs **inside the cluster**
* More fault-tolerant
* Preferred for production

---

## ­ЪћЪ Narrow Transformations

Transformations where:

* Each output partition depends on **one input partition**
* No shuffle required

Examples:

* `map`
* `filter`
* `select`

­ЪћЦ Fast & efficient

---

## 1№ИЈРЃБ1№ИЈРЃБ Lazy Operation

Spark transformations are **lazy**.

* Nothing executes until an **action**
* Allows Spark to optimize execution

Example:

```python
df.filter(...).select(...)
```

No execution yet.

---

## 1№ИЈРЃБ2№ИЈРЃБ Wide Transformations

Transformations where:

* Output depends on **multiple input partitions**
* Requires **shuffle**

Examples:

* `groupBy`
* `join`
* `distinct`

Рџа№ИЈ Expensive

---

## 1№ИЈРЃБ3№ИЈРЃБ Actions

Actions **trigger execution**.
Examples:

* `count`
* `collect`
* `save`
* `show`

Each action Рєњ **new job**

---

## 1№ИЈРЃБ4№ИЈРЃБ Shuffle

Shuffle is:

* Redistributing data across executors
* Disk + network intensive
* Happens during wide transformations

Major performance bottleneck.

---

## 1№ИЈРЃБ5№ИЈРЃБ Unresolved Logical Plan

Initial plan created from code.

* Column names not yet validated
* No schema binding

Example:

```sql
SELECT name FROM table
```

(Table may not exist yet)

---

## 1№ИЈРЃБ6№ИЈРЃБ Logical Plan

Resolved version of logical plan.

* Columns, tables verified
* Schema attached
* Still **not executable**

---

## 1№ИЈРЃБ7№ИЈРЃБ Filter Pushdown

Optimization where:

* Filters are applied **at data source**
* Less data read into Spark

Example:

```sql
WHERE date = '2025-01-01'
```

---

## 1№ИЈРЃБ8№ИЈРЃБ Projection Pushdown

Only required columns are read.

* Avoids reading unnecessary columns
* Improves IO performance

---

## 1№ИЈРЃБ9№ИЈРЃБ Physical Plan

Actual execution plan.

* Specifies joins, scans, shuffles
* Uses Spark operators
* Executed by executors

---

## 2№ИЈРЃБ0№ИЈРЃБ Catalyst Optimizer

Spark SQLРђЎs optimization engine.
Performs:

* Predicate pushdown
* Constant folding
* Join reordering
* Column pruning

­ЪћЦ Key reason Spark SQL is fast

---

## 2№ИЈРЃБ1№ИЈРЃБ Job

A **job** is created for every action.

* One action = one job
* A job = multiple stages

---

## 2№ИЈРЃБ2№ИЈРЃБ Stage

A stage is:

* A set of tasks with **no shuffle between them**
* Divided by shuffle boundaries

Types:

* ShuffleMapStage
* ResultStage

---

## 2№ИЈРЃБ3№ИЈРЃБ Task

Smallest unit of execution.

* One task per partition
* Executed on executors

­ЪЉЅ 100 partitions = 100 tasks

---

## 2№ИЈРЃБ4№ИЈРЃБ On Heap Memory

Memory managed by JVM.
Used for:

* Execution
* Storage
* User objects

Рџа№ИЈ Subject to JVM GC overhead

---

## 2№ИЈРЃБ5№ИЈРЃБ Execution Memory

Used for:

* Shuffles
* Joins
* Aggregations
* Sorts

Dynamic & released after task completion.

---

## 2№ИЈРЃБ6№ИЈРЃБ Storage Memory

Used for:

* Cached DataFrames/RDDs
* Broadcast variables

Can spill to disk if insufficient.

---

## 2№ИЈРЃБ7№ИЈРЃБ User Memory

Used for:

* User-defined data structures
* Python objects
* UDFs

Spark doesnРђЎt manage it directly.

---

## 2№ИЈРЃБ8№ИЈРЃБ Reserved Memory

Memory reserved by Spark internally.

* For system stability
* Not available for user tasks

Prevents OOM errors.

---

## 2№ИЈРЃБ9№ИЈРЃБ Off Heap Memory

Memory outside JVM heap.

* Uses native memory
* Avoids GC pressure
* Enabled via `spark.memory.offHeap.enabled`

Used heavily with **Tungsten engine**.

---

## 3№ИЈРЃБ0№ИЈРЃБ Overhead Memory

Extra memory for:

* JVM overhead
* Native libraries
* Python processes

Configured as:

```text
spark.executor.memoryOverhead
```

---

## ­ЪДа Final Mental Model (Interview Gold)

> **Code Рєњ Logical Plan Рєњ Catalyst Рєњ Physical Plan Рєњ DAG Рєњ Jobs Рєњ Stages Рєњ Tasks Рєњ Executors Рєњ Memory**

---

If you want next:

* ­ЪћЦ **Real-world performance tuning examples**
* ­ЪћЦ **Diagram-based explanation for interviews**
* ­ЪћЦ **Tricky interview questions from these concepts**

Just tell me ­ЪЉЇ
