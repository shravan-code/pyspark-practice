{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T12:46:57.313195400Z",
     "start_time": "2026-02-04T12:46:57.272208600Z"
    }
   },
   "cell_type": "code",
   "source": "import pyspark",
   "id": "eb1c6443ebb17866",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "625728b6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ‚úÖ PySpark Top 100 Methods ‚Äî **PART 1 (1‚Äì25)**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Category: DataFrame Creation, Selection, Filtering, Transformation**\n"
   ],
   "id": "72f826b1b05ba652"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## 1Ô∏è‚É£ `SparkSession.builder.getOrCreate()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Creates or retrieves the active Spark session.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Entry point for **all PySpark operations** (DataFrame, SQL, streaming).\n",
    "\n",
    "### **How**"
   ],
   "id": "453c52e336f18993"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T12:56:44.547924700Z",
     "start_time": "2026-02-04T12:56:31.475317800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".master(\"local[*]\") \\\n",
    ".config(\"spark.app.name\", \"MyApp\") \\\n",
    ".config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    ".config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    ".config(\"spark.driver.port\", 4040) \\\n",
    ".config(\"spark.blockManager.port\", 4041) \\\n",
    ".getOrCreate()\n"
   ],
   "id": "c5d39eb0b59c4e2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "3063e1bc",
   "metadata": {},
   "source": [
    "### **When / Scenario**\n",
    "\n",
    "* First line in **every PySpark job**\n",
    "* Required for DataFrame & SQL APIs\n",
    "\n",
    "### **Interview Tip**\n",
    "\n",
    "> SparkSession **replaced SparkContext + SQLContext + HiveContext**\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 2Ô∏è‚É£ `spark.read`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Entry point to read external data.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Supports multiple formats (CSV, JSON, Parquet, ORC, Avro).\n",
    "\n",
    "### **How**"
   ],
   "id": "c360da5ee45b97ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T12:56:47.858195700Z",
     "start_time": "2026-02-04T12:56:47.825810300Z"
    }
   },
   "cell_type": "code",
   "source": "import pathlib",
   "id": "c5c40c9a7783830d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T12:56:49.373605900Z",
     "start_time": "2026-02-04T12:56:49.265540200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "filepath = str(pathlib.Path().cwd().parent / 'data' / 'Spotify_Artists.csv')\n",
    "filepath"
   ],
   "id": "f3ba29730f41403d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\shra1\\\\github\\\\pyspark-practice\\\\data\\\\Spotify_Artists.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a0d183cc",
   "metadata": {
    "language": "python",
    "ExecuteTime": {
     "end_time": "2026-02-04T12:56:56.616925800Z",
     "start_time": "2026-02-04T12:56:51.097606200Z"
    }
   },
   "source": [
    "df = spark.read.csv(filepath,\n",
    "                    header=True,\n",
    "                    inferSchema=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T12:56:58.549835200Z",
     "start_time": "2026-02-04T12:56:57.952719700Z"
    }
   },
   "cell_type": "code",
   "source": "df.show(5)",
   "id": "b26470a21cb3043d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+---------+\n",
      "|artist_id|    name|     genre|  country|\n",
      "+---------+--------+----------+---------+\n",
      "|        1|Artist_1|Electronic|   France|\n",
      "|        2|Artist_2|Electronic|Australia|\n",
      "|        3|Artist_3|      Jazz|   France|\n",
      "|        4|Artist_4| Classical|Australia|\n",
      "|        5|Artist_5|   Hip-Hop|      USA|\n",
      "+---------+--------+----------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ff60f68b",
   "metadata": {},
   "source": [
    "### **Scenario**\n",
    "\n",
    "* Data ingestion layer\n",
    "* Batch pipelines\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## 3Ô∏è‚É£ `spark.read.format()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Explicitly defines file format.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Needed for advanced formats (Parquet, Delta, JDBC).\n",
    "\n",
    "### **How**"
   ],
   "id": "b6bdf3e032fbcf4a"
  },
  {
   "cell_type": "code",
   "id": "5d7d1eea",
   "metadata": {
    "language": "python",
    "ExecuteTime": {
     "end_time": "2026-02-04T12:47:55.396665700Z",
     "start_time": "2026-02-04T12:47:55.334121Z"
    }
   },
   "source": "# df = spark.read.format(\"parquet\").load(\"s3://bucket/data\")",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "b0bbc09f",
   "metadata": {},
   "source": [
    "### **Interview Angle**\n",
    "\n",
    "> Preferred over `.csv()` / `.json()` in **production pipelines**\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## 4Ô∏è‚É£ `spark.read.option()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Sets read-time options.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Controls parsing behavior (delimiter, schema, encoding).\n",
    "\n",
    "### **How**"
   ],
   "id": "2aa7bb5bcc1d064"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59a93b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": "# df = spark.read.option(\"delimiter\", \"|\").csv(\"data.txt\")"
  },
  {
   "cell_type": "markdown",
   "id": "3898b792",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 5Ô∏è‚É£ `df.show()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Displays rows.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Quick debugging & inspection.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "id": "983f74fe",
   "metadata": {
    "language": "python",
    "ExecuteTime": {
     "end_time": "2026-02-04T12:57:11.675894600Z",
     "start_time": "2026-02-04T12:57:11.400795500Z"
    }
   },
   "source": [
    "df.show(5, truncate=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+---------+\n",
      "|artist_id|name    |genre     |country  |\n",
      "+---------+--------+----------+---------+\n",
      "|1        |Artist_1|Electronic|France   |\n",
      "|2        |Artist_2|Electronic|Australia|\n",
      "|3        |Artist_3|Jazz      |France   |\n",
      "|4        |Artist_4|Classical |Australia|\n",
      "|5        |Artist_5|Hip-Hop   |USA      |\n",
      "+---------+--------+----------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "d8b648e8",
   "metadata": {},
   "source": [
    "### **Interview Trick**\n",
    "\n",
    "> `show()` **triggers an action**\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## 6Ô∏è‚É£ `df.printSchema()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Displays schema tree.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Critical for **debugging type issues**.\n",
    "\n",
    "### **How**"
   ],
   "id": "c9a121771b27942c"
  },
  {
   "cell_type": "code",
   "id": "084d6eea",
   "metadata": {
    "language": "python",
    "ExecuteTime": {
     "end_time": "2026-02-04T12:57:15.724401100Z",
     "start_time": "2026-02-04T12:57:15.619552700Z"
    }
   },
   "source": [
    "df.printSchema()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "8c994c27",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 7Ô∏è‚É£ `df.schema`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Returns schema object.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Used for **programmatic schema validation**.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "id": "be37d8cd",
   "metadata": {
    "language": "python",
    "ExecuteTime": {
     "end_time": "2026-02-04T12:57:18.752760900Z",
     "start_time": "2026-02-04T12:57:18.647050600Z"
    }
   },
   "source": [
    "df.schema"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('artist_id', IntegerType(), True), StructField('name', StringType(), True), StructField('genre', StringType(), True), StructField('country', StringType(), True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "68f49667",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 8Ô∏è‚É£ `df.select()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Selects columns.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Column pruning ‚Üí performance optimization.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f38cce6",
   "metadata": {
    "language": "python",
    "ExecuteTime": {
     "end_time": "2026-02-04T12:57:21.994225200Z",
     "start_time": "2026-02-04T12:57:21.629161700Z"
    }
   },
   "source": "df.select(\"name\", \"country\").show(5)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|    name|  country|\n",
      "+--------+---------+\n",
      "|Artist_1|   France|\n",
      "|Artist_2|Australia|\n",
      "|Artist_3|   France|\n",
      "|Artist_4|Australia|\n",
      "|Artist_5|      USA|\n",
      "+--------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "e8ec47ce",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 9Ô∏è‚É£ `df.selectExpr()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Select using SQL expressions.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Cleaner transformations without `withColumn`.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "id": "0cf3af08",
   "metadata": {
    "language": "python",
    "ExecuteTime": {
     "end_time": "2026-02-04T12:57:25.614010300Z",
     "start_time": "2026-02-04T12:57:24.559311800Z"
    }
   },
   "source": "df.selectExpr(\"country as nation\").show(5)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|   nation|\n",
      "+---------+\n",
      "|   France|\n",
      "|Australia|\n",
      "|   France|\n",
      "|Australia|\n",
      "|      USA|\n",
      "+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "170fe7cd",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Faster for **simple derived columns**\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## üîü `df.withColumn()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Adds or replaces a column.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Core transformation API.\n",
    "\n",
    "### **How**"
   ],
   "id": "452c9fd67d467809"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T12:57:56.597493900Z",
     "start_time": "2026-02-04T12:57:53.999640700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\"id_with_name\", col(\"artist_id\").cast(\"string\") + \"_\" + col(\"name\"))\n",
    "df.show(5)"
   ],
   "id": "fc30830fab977ed2",
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] No connection could be made because the target machine actively refused it",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mConnectionResetError\u001B[39m                      Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\py4j\\clientserver.py:527\u001B[39m, in \u001B[36mClientServerConnection.send_command\u001B[39m\u001B[34m(self, command)\u001B[39m\n\u001B[32m    526\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m527\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msocket\u001B[49m\u001B[43m.\u001B[49m\u001B[43msendall\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    528\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[31mConnectionResetError\u001B[39m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mPy4JNetworkError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\py4j\\java_gateway.py:1038\u001B[39m, in \u001B[36mGatewayClient.send_command\u001B[39m\u001B[34m(self, command, retry, binary)\u001B[39m\n\u001B[32m   1037\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1038\u001B[39m     response = \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1039\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m binary:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\py4j\\clientserver.py:530\u001B[39m, in \u001B[36mClientServerConnection.send_command\u001B[39m\u001B[34m(self, command)\u001B[39m\n\u001B[32m    529\u001B[39m     logger.info(\u001B[33m\"\u001B[39m\u001B[33mError while sending or receiving.\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m530\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JNetworkError(\n\u001B[32m    531\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mError while sending\u001B[39m\u001B[33m\"\u001B[39m, e, proto.ERROR_ON_SEND)\n\u001B[32m    533\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[31mPy4JNetworkError\u001B[39m: Error while sending",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mConnectionRefusedError\u001B[39m                    Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpyspark\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msql\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunctions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m col\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m df = df.withColumn(\u001B[33m\"\u001B[39m\u001B[33mid_with_name\u001B[39m\u001B[33m\"\u001B[39m, \u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43martist_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m.cast(\u001B[33m\"\u001B[39m\u001B[33mstring\u001B[39m\u001B[33m\"\u001B[39m) + \u001B[33m\"\u001B[39m\u001B[33m_\u001B[39m\u001B[33m\"\u001B[39m + col(\u001B[33m\"\u001B[39m\u001B[33mname\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m      4\u001B[39m df.show(\u001B[32m5\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\sql\\utils.py:282\u001B[39m, in \u001B[36mtry_remote_functions.<locals>.wrapped\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    280\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(functions, f.\u001B[34m__name__\u001B[39m)(*args, **kwargs)\n\u001B[32m    281\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m282\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\errors\\utils.py:306\u001B[39m, in \u001B[36m_with_origin.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    304\u001B[39m         set_current_origin(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    305\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m     spark = \u001B[43mSparkSession\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetActiveSession\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    307\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m spark \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    308\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\sql\\utils.py:357\u001B[39m, in \u001B[36mtry_remote_session_classmethod.<locals>.wrapped\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    355\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(SparkSession, f.\u001B[34m__name__\u001B[39m)(*args[\u001B[32m1\u001B[39m:], **kwargs)\n\u001B[32m    356\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m357\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\sql\\session.py:747\u001B[39m, in \u001B[36mSparkSession.getActiveSession\u001B[39m\u001B[34m(cls)\u001B[39m\n\u001B[32m    745\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    746\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m sc._jvm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m747\u001B[39m     jSparkSessionClass = \u001B[43mSparkSession\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_get_j_spark_session_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43msc\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_jvm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    748\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m jSparkSessionClass.getActiveSession().isDefined():\n\u001B[32m    749\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m SparkSession._should_update_active_session():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\sql\\session.py:669\u001B[39m, in \u001B[36mSparkSession._get_j_spark_session_class\u001B[39m\u001B[34m(jvm)\u001B[39m\n\u001B[32m    667\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m    668\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_get_j_spark_session_class\u001B[39m(jvm: \u001B[33m\"\u001B[39m\u001B[33mJVMView\u001B[39m\u001B[33m\"\u001B[39m) -> \u001B[33m\"\u001B[39m\u001B[33mJavaClass\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m669\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mjvm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43morg.apache.spark.sql.classic.SparkSession\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\py4j\\java_gateway.py:1752\u001B[39m, in \u001B[36mJVMView.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1749\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m name == UserHelpAutoCompletion.KEY:\n\u001B[32m   1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m UserHelpAutoCompletion()\n\u001B[32m-> \u001B[39m\u001B[32m1752\u001B[39m answer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_gateway_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1753\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproto\u001B[49m\u001B[43m.\u001B[49m\u001B[43mREFLECTION_COMMAND_NAME\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\n\u001B[32m   1754\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproto\u001B[49m\u001B[43m.\u001B[49m\u001B[43mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_id\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\n\u001B[32m   1755\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mproto\u001B[49m\u001B[43m.\u001B[49m\u001B[43mEND_COMMAND_PART\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1756\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m answer == proto.SUCCESS_PACKAGE:\n\u001B[32m   1757\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m JavaPackage(name, \u001B[38;5;28mself\u001B[39m._gateway_client, jvm_id=\u001B[38;5;28mself\u001B[39m._id)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\py4j\\java_gateway.py:1057\u001B[39m, in \u001B[36mGatewayClient.send_command\u001B[39m\u001B[34m(self, command, retry, binary)\u001B[39m\n\u001B[32m   1055\u001B[39m         retry = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   1056\u001B[39m     logging.info(\u001B[33m\"\u001B[39m\u001B[33mException while sending command.\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m1057\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbinary\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbinary\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1058\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1059\u001B[39m     logging.exception(\n\u001B[32m   1060\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mException while sending command.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\py4j\\java_gateway.py:1036\u001B[39m, in \u001B[36mGatewayClient.send_command\u001B[39m\u001B[34m(self, command, retry, binary)\u001B[39m\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msend_command\u001B[39m(\u001B[38;5;28mself\u001B[39m, command, retry=\u001B[38;5;28;01mTrue\u001B[39;00m, binary=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m   1016\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001B[39;00m\n\u001B[32m   1017\u001B[39m \u001B[33;03m       called directly by Py4J users. It is usually called by\u001B[39;00m\n\u001B[32m   1018\u001B[39m \u001B[33;03m       :class:`JavaMember` instances.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1034\u001B[39m \u001B[33;03m     if `binary` is `True`.\u001B[39;00m\n\u001B[32m   1035\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1036\u001B[39m     connection = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1037\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1038\u001B[39m         response = connection.send_command(command)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\py4j\\clientserver.py:284\u001B[39m, in \u001B[36mJavaClient._get_connection\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    281\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    283\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m connection \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m connection.socket \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m284\u001B[39m     connection = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_create_new_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\py4j\\clientserver.py:291\u001B[39m, in \u001B[36mJavaClient._create_new_connection\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_create_new_connection\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    288\u001B[39m     connection = ClientServerConnection(\n\u001B[32m    289\u001B[39m         \u001B[38;5;28mself\u001B[39m.java_parameters, \u001B[38;5;28mself\u001B[39m.python_parameters,\n\u001B[32m    290\u001B[39m         \u001B[38;5;28mself\u001B[39m.gateway_property, \u001B[38;5;28mself\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m291\u001B[39m     \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconnect_to_java_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    292\u001B[39m     \u001B[38;5;28mself\u001B[39m.set_thread_connection(connection)\n\u001B[32m    293\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\py4j\\clientserver.py:438\u001B[39m, in \u001B[36mClientServerConnection.connect_to_java_server\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    435\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ssl_context:\n\u001B[32m    436\u001B[39m     \u001B[38;5;28mself\u001B[39m.socket = \u001B[38;5;28mself\u001B[39m.ssl_context.wrap_socket(\n\u001B[32m    437\u001B[39m         \u001B[38;5;28mself\u001B[39m.socket, server_hostname=\u001B[38;5;28mself\u001B[39m.java_address)\n\u001B[32m--> \u001B[39m\u001B[32m438\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msocket\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mjava_address\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mjava_port\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    439\u001B[39m \u001B[38;5;28mself\u001B[39m.stream = \u001B[38;5;28mself\u001B[39m.socket.makefile(\u001B[33m\"\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    440\u001B[39m \u001B[38;5;28mself\u001B[39m.is_connected = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[31mConnectionRefusedError\u001B[39m: [WinError 10061] No connection could be made because the target machine actively refused it"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "910cc4e4",
   "metadata": {},
   "source": [
    "### **Interview Warning**\n",
    "\n",
    "> Multiple `withColumn()` calls = **multiple DAG stages**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ `df.withColumnRenamed()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Renames a column.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079d97a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"sal\", \"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e7c475",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ `df.drop()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Removes columns.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Reduce memory & shuffle size.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a036d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.drop(\"temp_col\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5d399",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£3Ô∏è‚É£ `df.filter()` / `df.where()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Row-level filtering.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Predicate pushdown optimization.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b241f3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.filter(col(\"salary\") > 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91598147",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> `filter()` and `where()` are **identical**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£4Ô∏è‚É£ `df.distinct()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Removes duplicate rows.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Data deduplication.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8131d0",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deea61f",
   "metadata": {},
   "source": [
    "### **Cost**\n",
    "\n",
    "‚ö†Ô∏è Triggers **shuffle**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£5Ô∏è‚É£ `df.dropDuplicates()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Removes duplicates based on columns.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2edb64",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.dropDuplicates([\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520791f6",
   "metadata": {},
   "source": [
    "### **Why**\n",
    "\n",
    "More control than `distinct()`\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£6Ô∏è‚É£ `df.orderBy()` / `df.sort()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Sorts rows.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04790577",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.orderBy(col(\"salary\").desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895efce",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Sorting causes **wide transformation (shuffle)**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£7Ô∏è‚É£ `df.limit()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Restricts number of rows.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Sampling / debugging.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623feb6c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb89b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£8Ô∏è‚É£ `df.sample()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Random sampling.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d64363",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.sample(fraction=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f7ee1",
   "metadata": {},
   "source": [
    "### **Scenario**\n",
    "\n",
    "* Model training\n",
    "* Data analysis\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£9Ô∏è‚É£ `df.count()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Counts rows.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Validation & metrics.\n",
    "\n",
    "### **Interview**\n",
    "\n",
    "> Very expensive on large datasets\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£0Ô∏è‚É£ `df.collect()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Brings data to driver.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Debugging small datasets.\n",
    "\n",
    "### **Danger**\n",
    "\n",
    "‚ùå **OOM risk**\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£1Ô∏è‚É£ `df.take()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Returns first N rows.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84ddec",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6875bb2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£2Ô∏è‚É£ `df.head()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Same as `take(1)`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£3Ô∏è‚É£ `df.columns`\n",
    "\n",
    "### **What**\n",
    "\n",
    "List of column names.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9a214",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24cb84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£4Ô∏è‚É£ `df.dtypes`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Column names with data types.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£5Ô∏è‚É£ `df.describe()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Basic statistics.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012dd89",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.describe(\"salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d0bd16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî• Interview Coverage Achieved (Part 1)\n",
    "\n",
    "‚úî Data ingestion\n",
    "‚úî Column operations\n",
    "‚úî Filtering\n",
    "‚úî Performance implications\n",
    "‚úî Lazy vs action operations\n",
    "\n",
    "---\n",
    "\n",
    "## üëâ Next Parts (coming next)\n",
    "\n",
    "**PART 2:** Aggregations, GroupBy, Joins (26‚Äì50)\n",
    "**PART 3:** Functions, Window, UDF, Date/JSON (51‚Äì75)\n",
    "**PART 4:** Performance, Partitioning, Caching, Writing, Spark Internals (76‚Äì100)\n",
    "\n",
    "If you want, I can:\n",
    "\n",
    "* Map **each method ‚Üí SQL equivalent**\n",
    "* Add **real interview questions per method**\n",
    "* Add **Spark execution plan & DAG explanations**\n",
    "\n",
    "Just say **‚ÄúContinue with Part 2‚Äù**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
