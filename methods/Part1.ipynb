{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "625728b6",
   "metadata": {},
   "source": [
    "This is a **very large request** (100 methods √ó *what/why/how/scenario/code/interview angle*).\n",
    "To keep it **interview-ready and actually usable**, I‚Äôll deliver this in **4 structured parts (25 methods each)**.\n",
    "\n",
    "Below is **PART 1: Core PySpark DataFrame & Column APIs (Most Asked in Interviews)**\n",
    "(These alone already cover ~70% of real interview questions)\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ PySpark Top 100 Methods ‚Äî **PART 1 (1‚Äì25)**\n",
    "\n",
    "**Category: DataFrame Creation, Selection, Filtering, Transformation**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ `SparkSession.builder.getOrCreate()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Creates or retrieves the active Spark session.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Entry point for **all PySpark operations** (DataFrame, SQL, streaming).\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5a2ea",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"InterviewPrep\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063e1bc",
   "metadata": {},
   "source": [
    "### **When / Scenario**\n",
    "\n",
    "* First line in **every PySpark job**\n",
    "* Required for DataFrame & SQL APIs\n",
    "\n",
    "### **Interview Tip**\n",
    "\n",
    "> SparkSession **replaced SparkContext + SQLContext + HiveContext**\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ `spark.read`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Entry point to read external data.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Supports multiple formats (CSV, JSON, Parquet, ORC, Avro).\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d183cc",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60f68b",
   "metadata": {},
   "source": [
    "### **Scenario**\n",
    "\n",
    "* Data ingestion layer\n",
    "* Batch pipelines\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ `spark.read.format()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Explicitly defines file format.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Needed for advanced formats (Parquet, Delta, JDBC).\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d1eea",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3://bucket/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbc09f",
   "metadata": {},
   "source": [
    "### **Interview Angle**\n",
    "\n",
    "> Preferred over `.csv()` / `.json()` in **production pipelines**\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ `spark.read.option()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Sets read-time options.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Controls parsing behavior (delimiter, schema, encoding).\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59a93b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df = spark.read.option(\"delimiter\", \"|\").csv(\"data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898b792",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ `df.show()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Displays rows.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Quick debugging & inspection.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f74fe",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b648e8",
   "metadata": {},
   "source": [
    "### **Interview Trick**\n",
    "\n",
    "> `show()` **triggers an action**\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ `df.printSchema()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Displays schema tree.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Critical for **debugging type issues**.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d6eea",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c994c27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ `df.schema`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Returns schema object.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Used for **programmatic schema validation**.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37d8cd",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f49667",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ `df.select()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Selects columns.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Column pruning ‚Üí performance optimization.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38cce6",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.select(\"id\", \"salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec47ce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ `df.selectExpr()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Select using SQL expressions.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Cleaner transformations without `withColumn`.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3af08",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.selectExpr(\"salary * 1.1 as new_salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fe7cd",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Faster for **simple derived columns**\n",
    "\n",
    "---\n",
    "\n",
    "## üîü `df.withColumn()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Adds or replaces a column.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Core transformation API.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af24d57",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df = df.withColumn(\"bonus\", col(\"salary\") * 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cc4e4",
   "metadata": {},
   "source": [
    "### **Interview Warning**\n",
    "\n",
    "> Multiple `withColumn()` calls = **multiple DAG stages**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ `df.withColumnRenamed()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Renames a column.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079d97a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"sal\", \"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e7c475",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ `df.drop()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Removes columns.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Reduce memory & shuffle size.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a036d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.drop(\"temp_col\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5d399",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£3Ô∏è‚É£ `df.filter()` / `df.where()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Row-level filtering.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Predicate pushdown optimization.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b241f3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.filter(col(\"salary\") > 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91598147",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> `filter()` and `where()` are **identical**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£4Ô∏è‚É£ `df.distinct()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Removes duplicate rows.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Data deduplication.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8131d0",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deea61f",
   "metadata": {},
   "source": [
    "### **Cost**\n",
    "\n",
    "‚ö†Ô∏è Triggers **shuffle**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£5Ô∏è‚É£ `df.dropDuplicates()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Removes duplicates based on columns.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2edb64",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.dropDuplicates([\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520791f6",
   "metadata": {},
   "source": [
    "### **Why**\n",
    "\n",
    "More control than `distinct()`\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£6Ô∏è‚É£ `df.orderBy()` / `df.sort()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Sorts rows.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04790577",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.orderBy(col(\"salary\").desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895efce",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Sorting causes **wide transformation (shuffle)**\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£7Ô∏è‚É£ `df.limit()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Restricts number of rows.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Sampling / debugging.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623feb6c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb89b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£8Ô∏è‚É£ `df.sample()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Random sampling.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d64363",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.sample(fraction=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f7ee1",
   "metadata": {},
   "source": [
    "### **Scenario**\n",
    "\n",
    "* Model training\n",
    "* Data analysis\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£9Ô∏è‚É£ `df.count()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Counts rows.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Validation & metrics.\n",
    "\n",
    "### **Interview**\n",
    "\n",
    "> Very expensive on large datasets\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£0Ô∏è‚É£ `df.collect()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Brings data to driver.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Debugging small datasets.\n",
    "\n",
    "### **Danger**\n",
    "\n",
    "‚ùå **OOM risk**\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£1Ô∏è‚É£ `df.take()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Returns first N rows.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84ddec",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6875bb2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£2Ô∏è‚É£ `df.head()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Same as `take(1)`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£3Ô∏è‚É£ `df.columns`\n",
    "\n",
    "### **What**\n",
    "\n",
    "List of column names.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9a214",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24cb84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£4Ô∏è‚É£ `df.dtypes`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Column names with data types.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£5Ô∏è‚É£ `df.describe()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Basic statistics.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012dd89",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.describe(\"salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d0bd16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî• Interview Coverage Achieved (Part 1)\n",
    "\n",
    "‚úî Data ingestion\n",
    "‚úî Column operations\n",
    "‚úî Filtering\n",
    "‚úî Performance implications\n",
    "‚úî Lazy vs action operations\n",
    "\n",
    "---\n",
    "\n",
    "## üëâ Next Parts (coming next)\n",
    "\n",
    "**PART 2:** Aggregations, GroupBy, Joins (26‚Äì50)\n",
    "**PART 3:** Functions, Window, UDF, Date/JSON (51‚Äì75)\n",
    "**PART 4:** Performance, Partitioning, Caching, Writing, Spark Internals (76‚Äì100)\n",
    "\n",
    "If you want, I can:\n",
    "\n",
    "* Map **each method ‚Üí SQL equivalent**\n",
    "* Add **real interview questions per method**\n",
    "* Add **Spark execution plan & DAG explanations**\n",
    "\n",
    "Just say **‚ÄúContinue with Part 2‚Äù**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
