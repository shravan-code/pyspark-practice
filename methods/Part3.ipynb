{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473f46d3",
   "metadata": {},
   "source": [
    "Continuing exactly as promised â€” **deep, interview-grade, scenario-driven**.\n",
    "\n",
    "---\n",
    "\n",
    "# âœ… PySpark Top 100 Methods â€” **PART 3 (51â€“75)**\n",
    "\n",
    "**Category: Window Functions, Built-in Functions, UDFs, Complex Types, Dates, JSON**\n",
    "\n",
    "These are **senior-level differentiators** in PySpark interviews.\n",
    "\n",
    "---\n",
    "\n",
    "## 5ï¸âƒ£1ï¸âƒ£ `Window.partitionBy().orderBy()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Defines window specification.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Required for window functions (ranking, running totals).\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4df5c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "w = Window.partitionBy(\"dept\").orderBy(\"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3e01f",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Window functions **do not reduce rows**\n",
    "\n",
    "---\n",
    "\n",
    "## 5ï¸âƒ£2ï¸âƒ£ `row_number()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Sequential numbering.\n",
    "\n",
    "### **Use Case**\n",
    "\n",
    "Deduplication, top-N.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770460b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import row_number\n",
    "df.withColumn(\"rn\", row_number().over(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d35d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5ï¸âƒ£3ï¸âƒ£ `rank()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Ranking with gaps.\n",
    "\n",
    "### **Interview**\n",
    "\n",
    "> Ties â†’ skipped numbers\n",
    "\n",
    "---\n",
    "\n",
    "## 5ï¸âƒ£4ï¸âƒ£ `dense_rank()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Ranking without gaps.\n",
    "\n",
    "---\n",
    "\n",
    "## 5ï¸âƒ£5ï¸âƒ£ `lead()` / `lag()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Access next/previous row.\n",
    "\n",
    "### **Use Case**\n",
    "\n",
    "Time-series comparisons.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9b2eb",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lag\n",
    "df.withColumn(\"prev_salary\", lag(\"salary\").over(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02cdbdc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5ï¸âƒ£6ï¸âƒ£ `sum().over()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Running total.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab563a07",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "df.withColumn(\"running_sum\", sum(\"salary\").over(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb1451",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5ï¸âƒ£7ï¸âƒ£ `when()` / `otherwise()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Conditional logic.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Replaces SQL CASE WHEN.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c406f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df.withColumn(\"grade\",\n",
    "    when(col(\"salary\") > 80000, \"A\")\n",
    "    .otherwise(\"B\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b860552",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5ï¸âƒ£8ï¸âƒ£ `lit()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Creates literal column.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc828b9e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.withColumn(\"country\", lit(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93629859",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5ï¸âƒ£9ï¸âƒ£ `concat()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Concatenates columns.\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£0ï¸âƒ£ `regexp_replace()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Regex substitution.\n",
    "\n",
    "### **Use Case**\n",
    "\n",
    "Data cleansing.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96acaa8",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "df.withColumn(\"phone\", regexp_replace(\"phone\", \"-\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5dce15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6ï¸âƒ£1ï¸âƒ£ `split()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Splits string into array.\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£2ï¸âƒ£ `explode()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Converts array â†’ rows.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8f855",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df.select(explode(\"skills\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4f1d1",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> `explode()` increases row count\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£3ï¸âƒ£ `collect_list()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Aggregates into array.\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£4ï¸âƒ£ `collect_set()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Unique values only.\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£5ï¸âƒ£ `to_date()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "String â†’ date.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3306a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "df.withColumn(\"dt\", to_date(\"date_str\", \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f0cc4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6ï¸âƒ£6ï¸âƒ£ `datediff()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Difference between dates.\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£7ï¸âƒ£ `current_date()` / `current_timestamp()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "System date/time.\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£8ï¸âƒ£ `year()` / `month()` / `dayofmonth()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Date extraction.\n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£9ï¸âƒ£ `from_json()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "JSON string â†’ struct.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa2bf2a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "df.withColumn(\"json_col\", from_json(\"raw_json\", schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c182a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7ï¸âƒ£0ï¸âƒ£ `to_json()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Struct â†’ JSON string.\n",
    "\n",
    "---\n",
    "\n",
    "## 7ï¸âƒ£1ï¸âƒ£ `get_json_object()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Extract JSON field.\n",
    "\n",
    "### **Interview**\n",
    "\n",
    "> Slower than `from_json`\n",
    "\n",
    "---\n",
    "\n",
    "## 7ï¸âƒ£2ï¸âƒ£ `udf()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "User-Defined Function.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Custom logic.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dca4cd",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "@udf(IntegerType())\n",
    "def square(x):\n",
    "    return x * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de6cfa",
   "metadata": {},
   "source": [
    "### **Interview Warning**\n",
    "\n",
    "âŒ **Avoid UDFs** if built-in exists\n",
    "\n",
    "---\n",
    "\n",
    "## 7ï¸âƒ£3ï¸âƒ£ `pandas_udf()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Vectorized UDF.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Much faster than normal UDF.\n",
    "\n",
    "---\n",
    "\n",
    "## 7ï¸âƒ£4ï¸âƒ£ `mapPartitions()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Processes partition-wise.\n",
    "\n",
    "### **Use Case**\n",
    "\n",
    "External API calls.\n",
    "\n",
    "---\n",
    "\n",
    "## 7ï¸âƒ£5ï¸âƒ£ `foreachPartition()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Side-effects (write to DB).\n",
    "\n",
    "### **Interview**\n",
    "\n",
    "> Used in **streaming sinks**\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ”¥ Interview Coverage (Part 3)\n",
    "\n",
    "âœ” Window analytics\n",
    "âœ” Complex types\n",
    "âœ” UDF vs built-in performance\n",
    "âœ” Date & JSON handling\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‘‰ Final Part:\n",
    "\n",
    "**PART 4 (76â€“100):**\n",
    "\n",
    "* Writing data\n",
    "* File formats\n",
    "* Partitioning strategies\n",
    "* Spark internals\n",
    "* Performance tuning\n",
    "* Streaming basics\n",
    "\n",
    "Say **â€œContinue Part 4â€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
