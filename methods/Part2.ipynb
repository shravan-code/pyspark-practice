{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c98835",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ✅ PySpark Top 100 Methods — **PART 2 (26–50)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ea480",
   "metadata": {},
   "source": [
    "\n",
    "**Category: Aggregations, GroupBy, Joins, Set Operations**\n",
    "\n",
    "These methods dominate **mid-level and senior data engineer interviews**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f30521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\shra1\\\\github\\\\pyspark-practice\\\\data\\\\Spotify_Songs.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "filepath = str(pathlib.Path().cwd().parent / \"data\" / \"Spotify_Songs.csv\")\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d34f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, expr, to_utc_timestamp, to_date, year, month, dayofmonth, hour, minute, second\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType, DoubleType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b30586",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparksession = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"song_id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"artist_id\", IntegerType(), True),\n",
    "    StructField(\"release_date\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "df = sparksession.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10234e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+--------------------------+\n",
      "|song_id|title  |artist_id|release_date              |\n",
      "+-------+-------+---------+--------------------------+\n",
      "|1      |Song_1 |2        |2021-10-15 10:15:47.006571|\n",
      "|2      |Song_2 |45       |2020-12-07 10:15:47.006588|\n",
      "|3      |Song_3 |25       |2022-07-11 10:15:47.006591|\n",
      "|4      |Song_4 |25       |2019-03-09 10:15:47.006593|\n",
      "|5      |Song_5 |26       |2019-09-07 10:15:47.006596|\n",
      "|6      |Song_6 |27       |2023-03-25 10:15:47.006598|\n",
      "|7      |Song_7 |34       |2023-01-07 10:15:47.006602|\n",
      "|8      |Song_8 |18       |2023-01-30 10:15:47.006604|\n",
      "|9      |Song_9 |14       |2020-05-21 10:15:47.006606|\n",
      "|10     |Song_10|1        |2021-09-26 10:15:47.006609|\n",
      "+-------+-------+---------+--------------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58472a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date\", to_date(df.release_date, \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134bbee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('song_id', IntegerType(), True), StructField('title', StringType(), True), StructField('artist_id', IntegerType(), True), StructField('release_date', TimestampType(), True), StructField('date', DateType(), True)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95cb66cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: integer (nullable = true)\n",
      " |-- release_date: timestamp (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f0b412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date\", dayofmonth(df.release_date)) \\\n",
    "    .withColumn(\"month\", month(df.release_date)) \\\n",
    "    .withColumn(\"year\", year(df.release_date)) \\\n",
    "    .withColumn(\"hour\", hour(df.release_date)) \\\n",
    "    .withColumn(\"minute\", minute(df.release_date)) \\\n",
    "    .withColumn(\"second\", second(df.release_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59817dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------------------+----+-----+----+----+------+------+\n",
      "|song_id| title|artist_id|        release_date|date|month|year|hour|minute|second|\n",
      "+-------+------+---------+--------------------+----+-----+----+----+------+------+\n",
      "|      1|Song_1|        2|2021-10-15 10:15:...|  15|   10|2021|  10|    15|    47|\n",
      "|      2|Song_2|       45|2020-12-07 10:15:...|   7|   12|2020|  10|    15|    47|\n",
      "|      3|Song_3|       25|2022-07-11 10:15:...|  11|    7|2022|  10|    15|    47|\n",
      "|      4|Song_4|       25|2019-03-09 10:15:...|   9|    3|2019|  10|    15|    47|\n",
      "|      5|Song_5|       26|2019-09-07 10:15:...|   7|    9|2019|  10|    15|    47|\n",
      "+-------+------+---------+--------------------+----+-----+----+----+------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922d1ba",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2️⃣6️⃣ `df.groupBy()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Groups rows based on column(s).\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Required for aggregations.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9e1dea1",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2018|1    |\n",
      "|2019|21   |\n",
      "|2020|25   |\n",
      "|2021|19   |\n",
      "|2022|15   |\n",
      "|2023|19   |\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"year\").count().sort(\"year\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86ef47",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> `groupBy()` alone does nothing — needs an aggregation\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣7️⃣ `agg()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Applies aggregate functions.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Multiple aggregations in one pass.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5c0cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, max, sum, min, count\n",
    "\n",
    "df_agg = df.groupBy(df.year).agg(\n",
    "    avg(df.month),\n",
    "    max(df.month),\n",
    "    sum(df.month),\n",
    "    min(df.month),\n",
    "    count(df.month)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72ba0181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+----------+----------+----------+------------+\n",
      "|year|avg(month)       |max(month)|sum(month)|min(month)|count(month)|\n",
      "+----+-----------------+----------+----------+----------+------------+\n",
      "|2018|11.0             |11        |11        |11        |1           |\n",
      "|2023|4.157894736842105|11        |79        |1         |19          |\n",
      "|2022|7.066666666666666|12        |106       |1         |15          |\n",
      "|2019|7.380952380952381|12        |155       |1         |21          |\n",
      "|2020|7.36             |12        |184       |1         |25          |\n",
      "|2021|6.473684210526316|10        |123       |1         |19          |\n",
      "+----+-----------------+----------+----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "910176cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- avg(month): double (nullable = true)\n",
      " |-- max(month): integer (nullable = true)\n",
      " |-- sum(month): long (nullable = true)\n",
      " |-- min(month): integer (nullable = true)\n",
      " |-- count(month): long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc07d905",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64be1edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2023|   19|\n",
      "|2022|   15|\n",
      "|2019|   21|\n",
      "|2020|   25|\n",
      "|2021|   19|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"year\").count().filter(col(\"count\") > 3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19ee33",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2️⃣9️⃣ `sum()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Computes sum.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6aaae79d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+\n",
      "|year|sum(artist_id)|\n",
      "+----+--------------+\n",
      "|2023|           519|\n",
      "|2022|           321|\n",
      "|2019|           611|\n",
      "|2020|           613|\n",
      "|2021|           412|\n",
      "+----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"year\").sum(\"artist_id\").filter(col(\"sum(artist_id)\") > 100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6171c7d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3️⃣0️⃣ `avg()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Average aggregation.\n",
    "\n",
    "### **Interview**\n",
    "\n",
    "> Uses **double precision** internally\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb0e1e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+--------------------+----+-----+----+----+------+------+\n",
      "|song_id|  title|artist_id|        release_date|date|month|year|hour|minute|second|\n",
      "+-------+-------+---------+--------------------+----+-----+----+----+------+------+\n",
      "|      1| Song_1|        2|2021-10-15 10:15:...|  15|   10|2021|  10|    15|    47|\n",
      "|      2| Song_2|       45|2020-12-07 10:15:...|   7|   12|2020|  10|    15|    47|\n",
      "|      3| Song_3|       25|2022-07-11 10:15:...|  11|    7|2022|  10|    15|    47|\n",
      "|      4| Song_4|       25|2019-03-09 10:15:...|   9|    3|2019|  10|    15|    47|\n",
      "|      5| Song_5|       26|2019-09-07 10:15:...|   7|    9|2019|  10|    15|    47|\n",
      "|      6| Song_6|       27|2023-03-25 10:15:...|  25|    3|2023|  10|    15|    47|\n",
      "|      7| Song_7|       34|2023-01-07 10:15:...|   7|    1|2023|  10|    15|    47|\n",
      "|      8| Song_8|       18|2023-01-30 10:15:...|  30|    1|2023|  10|    15|    47|\n",
      "|      9| Song_9|       14|2020-05-21 10:15:...|  21|    5|2020|  10|    15|    47|\n",
      "|     10|Song_10|        1|2021-09-26 10:15:...|  26|    9|2021|  10|    15|    47|\n",
      "|     11|Song_11|       12|2023-02-28 10:15:...|  28|    2|2023|  10|    15|    47|\n",
      "|     12|Song_12|       50|2020-12-02 10:15:...|   2|   12|2020|  10|    15|    47|\n",
      "|     13|Song_13|       46|2019-07-01 10:15:...|   1|    7|2019|  10|    15|    47|\n",
      "|     14|Song_14|       36|2019-06-11 10:15:...|  11|    6|2019|  10|    15|    47|\n",
      "|     15|Song_15|       13|2023-01-23 10:15:...|  23|    1|2023|  10|    15|    47|\n",
      "|     16|Song_16|        1|2020-12-21 10:15:...|  21|   12|2020|  10|    15|    47|\n",
      "|     17|Song_17|       23|2021-03-16 10:15:...|  16|    3|2021|  10|    15|    47|\n",
      "|     18|Song_18|        6|2022-04-29 10:15:...|  29|    4|2022|  10|    15|    47|\n",
      "|     19|Song_19|       12|2020-11-04 10:15:...|   4|   11|2020|  10|    15|    47|\n",
      "|     20|Song_20|        7|2023-04-04 10:15:...|   4|    4|2023|  10|    15|    47|\n",
      "+-------+-------+---------+--------------------+----+-----+----+----+------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d04ae1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|    avg(artist_id)|\n",
      "+----+------------------+\n",
      "|2018|              38.0|\n",
      "|2023| 27.31578947368421|\n",
      "|2022|              21.4|\n",
      "|2019|29.095238095238095|\n",
      "|2020|             24.52|\n",
      "+----+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"year\").avg(\"artist_id\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d297a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3️⃣1️⃣ `min()` / `max()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Minimum / maximum value.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6bab45b",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+\n",
      "|year|min(artist_id)|\n",
      "+----+--------------+\n",
      "|2018|            38|\n",
      "|2023|             7|\n",
      "|2022|             1|\n",
      "|2019|             1|\n",
      "|2020|             1|\n",
      "+----+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"year\").min(\"artist_id\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67cb9c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+\n",
      "|year|max(artist_id)|\n",
      "+----+--------------+\n",
      "|2018|            38|\n",
      "|2023|            50|\n",
      "|2022|            50|\n",
      "|2019|            47|\n",
      "|2020|            50|\n",
      "+----+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"year\").max(\"artist_id\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe170d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3️⃣2️⃣ `countDistinct()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Counts unique values.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9868a06",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT year)|\n",
      "+--------------------+\n",
      "|                   6|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df.select(countDistinct(\"year\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6f186",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Expensive → requires shuffle\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣3️⃣ `approx_count_distinct()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Approximate distinct count.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Massive performance gain.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "839327a8",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|approx_count_distinct(year)|\n",
      "+---------------------------+\n",
      "|                          6|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "\n",
    "\n",
    "df.select(approx_count_distinct(\"year\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01373d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2018|\n",
      "|2023|\n",
      "|2022|\n",
      "|2019|\n",
      "|2020|\n",
      "|2021|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"year\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16055fe1",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Uses **HyperLogLog++**\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣4️⃣ `pivot()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Converts rows → columns.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23674be",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"dept\").pivot(\"year\").sum(\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f3b14e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+----+----+----+----+\n",
      "|month|2018|2019|2020|2021|2022|2023|\n",
      "+-----+----+----+----+----+----+----+\n",
      "|    1|   0|   1|   1|   2|   1|   5|\n",
      "|    2|   0|   0|   5|   1|   0|   2|\n",
      "|    3|   0|   3|   0|   1|   0|   2|\n",
      "|    4|   0|   0|   1|   1|   2|   3|\n",
      "|    5|   0|   2|   1|   1|   0|   3|\n",
      "|    6|   0|   2|   2|   0|   1|   0|\n",
      "|    7|   0|   3|   2|   5|   6|   1|\n",
      "|    8|   0|   2|   1|   2|   2|   0|\n",
      "|    9|   0|   2|   3|   4|   0|   1|\n",
      "|   10|   0|   2|   1|   2|   1|   1|\n",
      "|   11|   1|   0|   3|   0|   1|   1|\n",
      "|   12|   0|   4|   5|   0|   1|   0|\n",
      "+-----+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stat = df.groupBy(\"month\").pivot(\"year\").count().sort(\"month\").fillna(0)\n",
    "df_stat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfa4c11",
   "metadata": {},
   "source": [
    "### **Use Case**\n",
    "\n",
    "* Reports\n",
    "* BI transformations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4e539a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_file = str(pathlib.Path().cwd().parent / \"data\" / \"Spotify_Artists.csv\")\n",
    "\n",
    "spotify_artists_schema = StructType([\n",
    "    StructField(\"artist_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"genre\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True)\n",
    "])\n",
    "\n",
    "artists_df = sparksession.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\") \\\n",
    "    .schema(spotify_artists_schema) \\\n",
    "    .csv(artists_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "000e588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+---------+\n",
      "|artist_id|    name|     genre|  country|\n",
      "+---------+--------+----------+---------+\n",
      "|        1|Artist_1|Electronic|   France|\n",
      "|        2|Artist_2|Electronic|Australia|\n",
      "|        3|Artist_3|      Jazz|   France|\n",
      "|        4|Artist_4| Classical|Australia|\n",
      "|        5|Artist_5|   Hip-Hop|      USA|\n",
      "+---------+--------+----------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "artists_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ca0bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listening_file = str(pathlib.Path().cwd().parent / \"data\" / \"Spotify_Listening_Activity.csv\")\n",
    "\n",
    "spotify_listening_schema = StructType([\n",
    "    StructField(\"activity_id\", IntegerType(), True),\n",
    "    StructField(\"song_id\", IntegerType(), True),\n",
    "    StructField(\"listen_date\", TimestampType(), True),\n",
    "    StructField(\"listen_duration\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "listening_df = sparksession.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\") \\\n",
    "    .schema(spotify_listening_schema) \\\n",
    "    .csv(listening_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29deb7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------+---------------+\n",
      "|activity_id|song_id|         listen_date|listen_duration|\n",
      "+-----------+-------+--------------------+---------------+\n",
      "|          1|     12|2023-06-27 10:15:...|             69|\n",
      "|          2|     44|2023-06-27 10:15:...|            300|\n",
      "|          3|     75|2023-06-27 10:15:...|             73|\n",
      "|          4|     48|2023-06-27 10:15:...|            105|\n",
      "|          5|     10|2023-06-27 10:15:...|            229|\n",
      "|          6|     82|2023-06-27 10:15:...|             35|\n",
      "|          7|     64|2023-06-27 10:15:...|            249|\n",
      "|          8|     96|2023-06-27 10:15:...|            211|\n",
      "|          9|     52|2023-06-27 10:15:...|             99|\n",
      "|         10|     21|2023-06-27 10:15:...|            181|\n",
      "|         11|      4|2023-06-27 10:15:...|            175|\n",
      "|         12|      6|2023-06-27 10:15:...|            244|\n",
      "|         13|     90|2023-06-27 10:15:...|            129|\n",
      "|         14|     33|2023-06-27 10:15:...|            260|\n",
      "|         15|      8|2023-06-27 10:15:...|            161|\n",
      "|         16|     93|2023-06-27 10:15:...|            141|\n",
      "|         17|     69|2023-06-27 10:15:...|            162|\n",
      "|         18|     97|2023-06-27 10:15:...|            275|\n",
      "|         19|     13|2023-06-27 10:15:...|             60|\n",
      "|         20|     92|2023-06-27 10:15:...|            134|\n",
      "+-----------+-------+--------------------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "listening_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6fb1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_file = str(pathlib.Path().cwd().parent / \"data\" / \"Spotify_Songs.csv\")\n",
    "\n",
    "spotify_songs_schema =  StructType([\n",
    "    StructField(\"song_id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"artist_id\", IntegerType(), True),\n",
    "    StructField(\"release_date\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "songs_df = sparksession.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\") \\\n",
    "    .schema(spotify_songs_schema) \\\n",
    "    .csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5eba4fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------------------+\n",
      "|song_id| title|artist_id|        release_date|\n",
      "+-------+------+---------+--------------------+\n",
      "|      1|Song_1|        2|2021-10-15 10:15:...|\n",
      "|      2|Song_2|       45|2020-12-07 10:15:...|\n",
      "|      3|Song_3|       25|2022-07-11 10:15:...|\n",
      "|      4|Song_4|       25|2019-03-09 10:15:...|\n",
      "|      5|Song_5|       26|2019-09-07 10:15:...|\n",
      "+-------+------+---------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "songs_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07b7e75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------------+---------------+------+-------+------+\n",
      "|activity_id|song_id|listen_date               |listen_duration|l_date|l_month|l_year|\n",
      "+-----------+-------+--------------------------+---------------+------+-------+------+\n",
      "|1          |12     |2023-06-27 10:15:47.008867|69             |27    |6      |2023  |\n",
      "|2          |44     |2023-06-27 10:15:47.008867|300            |27    |6      |2023  |\n",
      "|3          |75     |2023-06-27 10:15:47.008867|73             |27    |6      |2023  |\n",
      "|4          |48     |2023-06-27 10:15:47.008867|105            |27    |6      |2023  |\n",
      "|5          |10     |2023-06-27 10:15:47.008867|229            |27    |6      |2023  |\n",
      "+-----------+-------+--------------------------+---------------+------+-------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "listening_df = listening_df.withColumn(\"l_date\", dayofmonth(\"listen_date\")) \\\n",
    "    .withColumn(\"l_month\", month(\"listen_date\")) \\\n",
    "    .withColumn(\"l_year\", year(\"listen_date\")) \n",
    "\n",
    "listening_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bfc675a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------------------+------+-------+------+\n",
      "|song_id| title|artist_id|        release_date|r_date|r_month|r_year|\n",
      "+-------+------+---------+--------------------+------+-------+------+\n",
      "|      1|Song_1|        2|2021-10-15 10:15:...|    15|     10|  2021|\n",
      "|      2|Song_2|       45|2020-12-07 10:15:...|     7|     12|  2020|\n",
      "|      3|Song_3|       25|2022-07-11 10:15:...|    11|      7|  2022|\n",
      "|      4|Song_4|       25|2019-03-09 10:15:...|     9|      3|  2019|\n",
      "|      5|Song_5|       26|2019-09-07 10:15:...|     7|      9|  2019|\n",
      "+-------+------+---------+--------------------+------+-------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "songs_df = songs_df.withColumn(\"r_date\", dayofmonth(\"release_date\")) \\\n",
    "    .withColumn(\"r_month\", month(\"release_date\")) \\\n",
    "    .withColumn(\"r_year\", year(\"release_date\")) \n",
    "    \n",
    "songs_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b07ec3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3️⃣5️⃣ `join()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Combines DataFrames.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68d63376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+---------+-------+------+--------------------------+------+-------+------+\n",
      "|artist_id|name     |genre     |country  |song_id|title |release_date              |r_date|r_month|r_year|\n",
      "+---------+---------+----------+---------+-------+------+--------------------------+------+-------+------+\n",
      "|2        |Artist_2 |Electronic|Australia|1      |Song_1|2021-10-15 10:15:47.006571|15    |10     |2021  |\n",
      "|45       |Artist_45|Electronic|UK       |2      |Song_2|2020-12-07 10:15:47.006588|7     |12     |2020  |\n",
      "|25       |Artist_25|Classical |Canada   |3      |Song_3|2022-07-11 10:15:47.006591|11    |7      |2022  |\n",
      "|25       |Artist_25|Classical |Canada   |4      |Song_4|2019-03-09 10:15:47.006593|9     |3      |2019  |\n",
      "|26       |Artist_26|Jazz      |France   |5      |Song_5|2019-09-07 10:15:47.006596|7     |9      |2019  |\n",
      "+---------+---------+----------+---------+-------+------+--------------------------+------+-------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "artist_songs_df = artists_df.join(songs_df, on=\"artist_id\", how=\"inner\")\n",
    "artist_songs_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7685c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+---------+\n",
      "|artist_id|     name|     genre|  country|\n",
      "+---------+---------+----------+---------+\n",
      "|        8| Artist_8|      Rock|  Germany|\n",
      "|       29|Artist_29| Classical|Australia|\n",
      "|       40|Artist_40|Electronic|      USA|\n",
      "|       41|Artist_41|   Hip-Hop|Australia|\n",
      "+---------+---------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.join(songs_df, on=\"artist_id\", how=\"anti\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec85a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3️⃣6️⃣ Join Types\n",
    "\n",
    "| Type  | Use             |\n",
    "| ----- | --------------- |\n",
    "| inner | Matching rows   |\n",
    "| left  | All left rows   |\n",
    "| right | All right rows  |\n",
    "| full  | All rows        |\n",
    "| semi  | Exists in right |\n",
    "| anti  | Not exists      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c0850cac",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+-----------+-------+-------+--------------------+------+-------+------+\n",
      "|artist_id|     name|     genre|    country|song_id|  title|        release_date|r_date|r_month|r_year|\n",
      "+---------+---------+----------+-----------+-------+-------+--------------------+------+-------+------+\n",
      "|        1| Artist_1|Electronic|     France|     10|Song_10|2021-09-26 10:15:...|    26|      9|  2021|\n",
      "|        1| Artist_1|Electronic|     France|     16|Song_16|2020-12-21 10:15:...|    21|     12|  2020|\n",
      "|        1| Artist_1|Electronic|     France|     22|Song_22|2021-07-19 10:15:...|    19|      7|  2021|\n",
      "|        1| Artist_1|Electronic|     France|     29|Song_29|2022-07-06 10:15:...|     6|      7|  2022|\n",
      "|        1| Artist_1|Electronic|     France|     43|Song_43|2021-04-20 10:15:...|    20|      4|  2021|\n",
      "|        1| Artist_1|Electronic|     France|     53|Song_53|2022-11-27 10:15:...|    27|     11|  2022|\n",
      "|        1| Artist_1|Electronic|     France|     90|Song_90|2019-05-10 10:15:...|    10|      5|  2019|\n",
      "|        2| Artist_2|Electronic|  Australia|      1| Song_1|2021-10-15 10:15:...|    15|     10|  2021|\n",
      "|        2| Artist_2|Electronic|  Australia|     54|Song_54|2020-09-28 10:15:...|    28|      9|  2020|\n",
      "|        3| Artist_3|      Jazz|     France|     73|Song_73|2020-12-08 10:15:...|     8|     12|  2020|\n",
      "|        4| Artist_4| Classical|  Australia|     66|Song_66|2022-08-16 10:15:...|    16|      8|  2022|\n",
      "|        4| Artist_4| Classical|  Australia|     84|Song_84|2021-05-07 10:15:...|     7|      5|  2021|\n",
      "|        5| Artist_5|   Hip-Hop|        USA|     69|Song_69|2020-07-05 10:15:...|     5|      7|  2020|\n",
      "|        6| Artist_6|      Jazz|  Australia|     18|Song_18|2022-04-29 10:15:...|    29|      4|  2022|\n",
      "|        6| Artist_6|      Jazz|  Australia|     75|Song_75|2021-09-23 10:15:...|    23|      9|  2021|\n",
      "|        6| Artist_6|      Jazz|  Australia|     99|Song_99|2022-08-26 10:15:...|    26|      8|  2022|\n",
      "|        7| Artist_7|      Jazz|South Korea|     20|Song_20|2023-04-04 10:15:...|     4|      4|  2023|\n",
      "|        8| Artist_8|      Rock|    Germany|   NULL|   NULL|                NULL|  NULL|   NULL|  NULL|\n",
      "|        9| Artist_9|      Jazz|      Japan|     41|Song_41|2023-01-11 10:15:...|    11|      1|  2023|\n",
      "|       10|Artist_10|      Rock|    Germany|     95|Song_95|2022-10-12 10:15:...|    12|     10|  2022|\n",
      "+---------+---------+----------+-----------+-------+-------+--------------------+------+-------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "artists_df.join(songs_df, \"artist_id\", \"outer\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfdb1b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3️⃣7️⃣ `broadcast()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Broadcasts small table.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Avoids shuffle.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dec9828b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 11779, 100)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_df.count(), listening_df.count(), songs_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6aaec1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+--------------------+------+-------+------+---------+----------+-----------+\n",
      "|artist_id|song_id|  title|        release_date|r_date|r_month|r_year|     name|     genre|    country|\n",
      "+---------+-------+-------+--------------------+------+-------+------+---------+----------+-----------+\n",
      "|        2|      1| Song_1|2021-10-15 10:15:...|    15|     10|  2021| Artist_2|Electronic|  Australia|\n",
      "|       45|      2| Song_2|2020-12-07 10:15:...|     7|     12|  2020|Artist_45|Electronic|         UK|\n",
      "|       25|      3| Song_3|2022-07-11 10:15:...|    11|      7|  2022|Artist_25| Classical|     Canada|\n",
      "|       25|      4| Song_4|2019-03-09 10:15:...|     9|      3|  2019|Artist_25| Classical|     Canada|\n",
      "|       26|      5| Song_5|2019-09-07 10:15:...|     7|      9|  2019|Artist_26|      Jazz|     France|\n",
      "|       27|      6| Song_6|2023-03-25 10:15:...|    25|      3|  2023|Artist_27|   Hip-Hop|     Canada|\n",
      "|       34|      7| Song_7|2023-01-07 10:15:...|     7|      1|  2023|Artist_34|Electronic|  Australia|\n",
      "|       18|      8| Song_8|2023-01-30 10:15:...|    30|      1|  2023|Artist_18|       Pop|     Canada|\n",
      "|       14|      9| Song_9|2020-05-21 10:15:...|    21|      5|  2020|Artist_14| Classical|        USA|\n",
      "|        1|     10|Song_10|2021-09-26 10:15:...|    26|      9|  2021| Artist_1|Electronic|     France|\n",
      "|       12|     11|Song_11|2023-02-28 10:15:...|    28|      2|  2023|Artist_12| Classical|     France|\n",
      "|       50|     12|Song_12|2020-12-02 10:15:...|     2|     12|  2020|Artist_50|      Rock|     France|\n",
      "|       46|     13|Song_13|2019-07-01 10:15:...|     1|      7|  2019|Artist_46|      Rock|        USA|\n",
      "|       36|     14|Song_14|2019-06-11 10:15:...|    11|      6|  2019|Artist_36|   Hip-Hop|South Korea|\n",
      "|       13|     15|Song_15|2023-01-23 10:15:...|    23|      1|  2023|Artist_13|Electronic|    Germany|\n",
      "|        1|     16|Song_16|2020-12-21 10:15:...|    21|     12|  2020| Artist_1|Electronic|     France|\n",
      "|       23|     17|Song_17|2021-03-16 10:15:...|    16|      3|  2021|Artist_23|   Hip-Hop|      Japan|\n",
      "|        6|     18|Song_18|2022-04-29 10:15:...|    29|      4|  2022| Artist_6|      Jazz|  Australia|\n",
      "|       12|     19|Song_19|2020-11-04 10:15:...|     4|     11|  2020|Artist_12| Classical|     France|\n",
      "|        7|     20|Song_20|2023-04-04 10:15:...|     4|      4|  2023| Artist_7|      Jazz|South Korea|\n",
      "+---------+-------+-------+--------------------+------+-------+------+---------+----------+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "songs_df.join(artists_df, on=\"artist_id\", how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2d712c07",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+--------------------+------+-------+------+---------+----------+-----------+\n",
      "|artist_id|song_id|  title|        release_date|r_date|r_month|r_year|     name|     genre|    country|\n",
      "+---------+-------+-------+--------------------+------+-------+------+---------+----------+-----------+\n",
      "|        2|      1| Song_1|2021-10-15 10:15:...|    15|     10|  2021| Artist_2|Electronic|  Australia|\n",
      "|       45|      2| Song_2|2020-12-07 10:15:...|     7|     12|  2020|Artist_45|Electronic|         UK|\n",
      "|       25|      3| Song_3|2022-07-11 10:15:...|    11|      7|  2022|Artist_25| Classical|     Canada|\n",
      "|       25|      4| Song_4|2019-03-09 10:15:...|     9|      3|  2019|Artist_25| Classical|     Canada|\n",
      "|       26|      5| Song_5|2019-09-07 10:15:...|     7|      9|  2019|Artist_26|      Jazz|     France|\n",
      "|       27|      6| Song_6|2023-03-25 10:15:...|    25|      3|  2023|Artist_27|   Hip-Hop|     Canada|\n",
      "|       34|      7| Song_7|2023-01-07 10:15:...|     7|      1|  2023|Artist_34|Electronic|  Australia|\n",
      "|       18|      8| Song_8|2023-01-30 10:15:...|    30|      1|  2023|Artist_18|       Pop|     Canada|\n",
      "|       14|      9| Song_9|2020-05-21 10:15:...|    21|      5|  2020|Artist_14| Classical|        USA|\n",
      "|        1|     10|Song_10|2021-09-26 10:15:...|    26|      9|  2021| Artist_1|Electronic|     France|\n",
      "|       12|     11|Song_11|2023-02-28 10:15:...|    28|      2|  2023|Artist_12| Classical|     France|\n",
      "|       50|     12|Song_12|2020-12-02 10:15:...|     2|     12|  2020|Artist_50|      Rock|     France|\n",
      "|       46|     13|Song_13|2019-07-01 10:15:...|     1|      7|  2019|Artist_46|      Rock|        USA|\n",
      "|       36|     14|Song_14|2019-06-11 10:15:...|    11|      6|  2019|Artist_36|   Hip-Hop|South Korea|\n",
      "|       13|     15|Song_15|2023-01-23 10:15:...|    23|      1|  2023|Artist_13|Electronic|    Germany|\n",
      "|        1|     16|Song_16|2020-12-21 10:15:...|    21|     12|  2020| Artist_1|Electronic|     France|\n",
      "|       23|     17|Song_17|2021-03-16 10:15:...|    16|      3|  2021|Artist_23|   Hip-Hop|      Japan|\n",
      "|        6|     18|Song_18|2022-04-29 10:15:...|    29|      4|  2022| Artist_6|      Jazz|  Australia|\n",
      "|       12|     19|Song_19|2020-11-04 10:15:...|     4|     11|  2020|Artist_12| Classical|     France|\n",
      "|        7|     20|Song_20|2023-04-04 10:15:...|     4|      4|  2023| Artist_7|      Jazz|South Korea|\n",
      "+---------+-------+-------+--------------------+------+-------+------+---------+----------+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "songs_df.join(broadcast(artists_df), on=\"artist_id\", how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2c725",
   "metadata": {},
   "source": [
    "### **Interview Gold**\n",
    "\n",
    "> Broadcast if **< 10–50 MB**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ccdb0d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3️⃣8️⃣ `crossJoin()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Cartesian product.\n",
    "\n",
    "### **Danger**\n",
    "\n",
    "❌ Extremely expensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "037d8f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_df.crossJoin(songs_df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749473f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3️⃣9️⃣ `union()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Row-wise union.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1f0004c9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# df1.union(df2) # should have same number of columns in both dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a46dd83",
   "metadata": {},
   "source": [
    "### **Requirement**\n",
    "\n",
    "> Same schema order\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣0️⃣ `unionByName()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Union by column name.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Schema mismatch safe.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9e675",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# df1.unionByName(df2, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a8319",
   "metadata": {},
   "source": [
    "* unionByName is schema-safe , columns order does not matter, Name-based matching\n",
    "* union is position-based, columns order matter, Position-based matching\n",
    "* unionAll is deprecated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59da63",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4️⃣1️⃣ `intersect()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Common rows.\n",
    "\n",
    "### **Cost**\n",
    "\n",
    "⚠️ Shuffle required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6cc4b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "|song_id|  title|artist_id|        release_date|r_date|r_month|r_year|\n",
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "|      3| Song_3|       25|2022-07-11 10:15:...|    11|      7|  2022|\n",
      "|      4| Song_4|       25|2019-03-09 10:15:...|     9|      3|  2019|\n",
      "|      7| Song_7|       34|2023-01-07 10:15:...|     7|      1|  2023|\n",
      "|      8| Song_8|       18|2023-01-30 10:15:...|    30|      1|  2023|\n",
      "|      9| Song_9|       14|2020-05-21 10:15:...|    21|      5|  2020|\n",
      "|     12|Song_12|       50|2020-12-02 10:15:...|     2|     12|  2020|\n",
      "|     13|Song_13|       46|2019-07-01 10:15:...|     1|      7|  2019|\n",
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_songs_df = songs_df.sample(fraction=0.5, seed=1).limit(7)\n",
    "sample_songs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c7030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "|song_id|  title|artist_id|        release_date|r_date|r_month|r_year|\n",
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "|      3| Song_3|       25|2022-07-11 10:15:...|    11|      7|  2022|\n",
      "|      9| Song_9|       14|2020-05-21 10:15:...|    21|      5|  2020|\n",
      "|     13|Song_13|       46|2019-07-01 10:15:...|     1|      7|  2019|\n",
      "|      7| Song_7|       34|2023-01-07 10:15:...|     7|      1|  2023|\n",
      "|      4| Song_4|       25|2019-03-09 10:15:...|     9|      3|  2019|\n",
      "|      8| Song_8|       18|2023-01-30 10:15:...|    30|      1|  2023|\n",
      "|     12|Song_12|       50|2020-12-02 10:15:...|     2|     12|  2020|\n",
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.intersect(sample_songs_df).show() # no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09910f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "|song_id|  title|artist_id|        release_date|r_date|r_month|r_year|\n",
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "|      3| Song_3|       25|2022-07-11 10:15:...|    11|      7|  2022|\n",
      "|      9| Song_9|       14|2020-05-21 10:15:...|    21|      5|  2020|\n",
      "|     13|Song_13|       46|2019-07-01 10:15:...|     1|      7|  2019|\n",
      "|      7| Song_7|       34|2023-01-07 10:15:...|     7|      1|  2023|\n",
      "|      4| Song_4|       25|2019-03-09 10:15:...|     9|      3|  2019|\n",
      "|      8| Song_8|       18|2023-01-30 10:15:...|    30|      1|  2023|\n",
      "|     12|Song_12|       50|2020-12-02 10:15:...|     2|     12|  2020|\n",
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.intersectAll(sample_songs_df).show() # preserves duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6af6c6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4️⃣2️⃣ `exceptAll()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Rows in DF1 not in DF2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6c07308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "|song_id|  title|artist_id|        release_date|r_date|r_month|r_year|\n",
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "|     22|Song_22|        1|2021-07-19 10:15:...|    19|      7|  2021|\n",
      "|      1| Song_1|        2|2021-10-15 10:15:...|    15|     10|  2021|\n",
      "|     39|Song_39|       42|2019-01-08 10:15:...|     8|      1|  2019|\n",
      "|     17|Song_17|       23|2021-03-16 10:15:...|    16|      3|  2021|\n",
      "|     85|Song_85|       39|2020-09-04 10:15:...|     4|      9|  2020|\n",
      "|     35|Song_35|       18|2019-09-16 10:15:...|    16|      9|  2019|\n",
      "|     73|Song_73|        3|2020-12-08 10:15:...|     8|     12|  2020|\n",
      "|     46|Song_46|       38|2018-11-21 10:15:...|    21|     11|  2018|\n",
      "|     71|Song_71|       33|2020-02-22 10:15:...|    22|      2|  2020|\n",
      "|     81|Song_81|       16|2020-11-10 10:15:...|    10|     11|  2020|\n",
      "|     60|Song_60|       50|2023-09-09 10:15:...|     9|      9|  2023|\n",
      "|     43|Song_43|        1|2021-04-20 10:15:...|    20|      4|  2021|\n",
      "|     45|Song_45|       43|2023-01-05 10:15:...|     5|      1|  2023|\n",
      "|     42|Song_42|       45|2019-08-07 10:15:...|     7|      8|  2019|\n",
      "|     66|Song_66|        4|2022-08-16 10:15:...|    16|      8|  2022|\n",
      "|     67|Song_67|       30|2021-07-08 10:15:...|     8|      7|  2021|\n",
      "|     31|Song_31|       15|2020-10-24 10:15:...|    24|     10|  2020|\n",
      "|     90|Song_90|        1|2019-05-10 10:15:...|    10|      5|  2019|\n",
      "|     70|Song_70|       32|2022-07-12 10:15:...|    12|      7|  2022|\n",
      "|     40|Song_40|       22|2022-06-18 10:15:...|    18|      6|  2022|\n",
      "+-------+-------+---------+--------------------+------+-------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "songs_df.exceptAll(sample_songs_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "203ca75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---------+------------+------+-------+------+\n",
      "|song_id|title|artist_id|release_date|r_date|r_month|r_year|\n",
      "+-------+-----+---------+------------+------+-------+------+\n",
      "+-------+-----+---------+------------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_songs_df.exceptAll(songs_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d6157",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4️⃣3️⃣ `having` (via filter)\n",
    "\n",
    "### **What**\n",
    "\n",
    "Filter after aggregation.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b8d221a1",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|r_year|count|\n",
      "+------+-----+\n",
      "|  2019|   21|\n",
      "|  2020|   25|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.groupBy(\"r_year\").count().filter(col(\"count\") > 20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f5edf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4️⃣4️⃣ `groupingSets()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Multiple groupings.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Advanced analytics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140eeea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5412db94",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4️⃣5️⃣ `rollup()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Hierarchical aggregation.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc5515",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.rollup(\"country\", \"state\").sum(\"sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2465aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4️⃣6️⃣ `cube()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "All combinations aggregation.\n",
    "\n",
    "### **Interview**\n",
    "\n",
    "> More expensive than `rollup`\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣7️⃣ `repartition()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Changes partition count (shuffle).\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc869752",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.repartition(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048bcb3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4️⃣8️⃣ `coalesce()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Reduce partitions (no shuffle).\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40ed87",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.coalesce(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445217b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4️⃣9️⃣ `explain()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Execution plan.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f089fd4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e491fc",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Know **Logical vs Physical Plan**\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣0️⃣ `cache()` / `persist()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Stores DF in memory.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998bd298",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a0d254",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Use before **multiple actions**\n",
    "\n",
    "---\n",
    "\n",
    "# 🔥 Interview Coverage (Part 2)\n",
    "\n",
    "✔ Aggregations\n",
    "✔ Joins (broadcast vs shuffle)\n",
    "✔ Set operations\n",
    "✔ Performance tuning\n",
    "\n",
    "---\n",
    "\n",
    "## 👉 Next:\n",
    "\n",
    "**PART 3 (51–75):**\n",
    "\n",
    "* Window functions\n",
    "* UDFs\n",
    "* JSON / Date / Array / Map functions\n",
    "* explode, collect_list\n",
    "* SQL functions vs DataFrame API\n",
    "\n",
    "Say **“Continue Part 3”**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
