{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c98835",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ‚úÖ PySpark Top 100 Methods ‚Äî **PART 2 (26‚Äì50)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ea480",
   "metadata": {},
   "source": [
    "\n",
    "**Category: Aggregations, GroupBy, Joins, Set Operations**\n",
    "\n",
    "These methods dominate **mid-level and senior data engineer interviews**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f30521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\shra1\\\\github\\\\pyspark-practice\\\\data\\\\Spotify_Songs.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "filepath = str(pathlib.Path().cwd().parent / \"data\" / \"Spotify_Songs.csv\")\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d34f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, expr, to_utc_timestamp, to_date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType, DoubleType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b30586",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparksession = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"song_id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"artist_id\", IntegerType(), True),\n",
    "    StructField(\"release_date\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "df = sparksession.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10234e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+--------------------------+\n",
      "|song_id|title  |artist_id|release_date              |\n",
      "+-------+-------+---------+--------------------------+\n",
      "|1      |Song_1 |2        |2021-10-15 10:15:47.006571|\n",
      "|2      |Song_2 |45       |2020-12-07 10:15:47.006588|\n",
      "|3      |Song_3 |25       |2022-07-11 10:15:47.006591|\n",
      "|4      |Song_4 |25       |2019-03-09 10:15:47.006593|\n",
      "|5      |Song_5 |26       |2019-09-07 10:15:47.006596|\n",
      "|6      |Song_6 |27       |2023-03-25 10:15:47.006598|\n",
      "|7      |Song_7 |34       |2023-01-07 10:15:47.006602|\n",
      "|8      |Song_8 |18       |2023-01-30 10:15:47.006604|\n",
      "|9      |Song_9 |14       |2020-05-21 10:15:47.006606|\n",
      "|10     |Song_10|1        |2021-09-26 10:15:47.006609|\n",
      "+-------+-------+---------+--------------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58472a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date\", to_date(df.release_date, \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134bbee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('song_id', IntegerType(), True), StructField('title', StringType(), True), StructField('artist_id', IntegerType(), True), StructField('release_date', TimestampType(), True), StructField('date', DateType(), True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95cb66cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: integer (nullable = true)\n",
      " |-- release_date: timestamp (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922d1ba",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2Ô∏è‚É£6Ô∏è‚É£ `df.groupBy()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Groups rows based on column(s).\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Required for aggregations.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9e1dea1",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|artist_id|count|\n",
      "+---------+-----+\n",
      "|31       |3    |\n",
      "|34       |2    |\n",
      "|28       |3    |\n",
      "|26       |4    |\n",
      "|27       |2    |\n",
      "|44       |2    |\n",
      "|12       |3    |\n",
      "|22       |1    |\n",
      "|47       |2    |\n",
      "|1        |7    |\n",
      "|13       |3    |\n",
      "|6        |3    |\n",
      "|16       |1    |\n",
      "|3        |1    |\n",
      "|20       |1    |\n",
      "|48       |1    |\n",
      "|5        |1    |\n",
      "|19       |1    |\n",
      "|15       |2    |\n",
      "|43       |3    |\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.artist_id).count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86ef47",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> `groupBy()` alone does nothing ‚Äî needs an aggregation\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£7Ô∏è‚É£ `agg()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Applies aggregate functions.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Multiple aggregations in one pass.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c0cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, max, sum, min, count\n",
    "\n",
    "df_agg = df.groupBy(df.artist_id).agg(\n",
    "    avg(df.artist_id),\n",
    "    max(df.artist_id),\n",
    "    sum(df.artist_id),\n",
    "    min(df.artist_id),\n",
    "    count(df.artist_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ba0181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+--------------+--------------+--------------+----------------+\n",
      "|artist_id|avg(artist_id)|max(artist_id)|sum(artist_id)|min(artist_id)|count(artist_id)|\n",
      "+---------+--------------+--------------+--------------+--------------+----------------+\n",
      "|31       |31.0          |31            |93            |31            |3               |\n",
      "|34       |34.0          |34            |68            |34            |2               |\n",
      "|28       |28.0          |28            |84            |28            |3               |\n",
      "|26       |26.0          |26            |104           |26            |4               |\n",
      "|27       |27.0          |27            |54            |27            |2               |\n",
      "|44       |44.0          |44            |88            |44            |2               |\n",
      "|12       |12.0          |12            |36            |12            |3               |\n",
      "|22       |22.0          |22            |22            |22            |1               |\n",
      "|47       |47.0          |47            |94            |47            |2               |\n",
      "|1        |1.0           |1             |7             |1             |7               |\n",
      "|13       |13.0          |13            |39            |13            |3               |\n",
      "|6        |6.0           |6             |18            |6             |3               |\n",
      "|16       |16.0          |16            |16            |16            |1               |\n",
      "|3        |3.0           |3             |3             |3             |1               |\n",
      "|20       |20.0          |20            |20            |20            |1               |\n",
      "|48       |48.0          |48            |48            |48            |1               |\n",
      "|5        |5.0           |5             |5             |5             |1               |\n",
      "|19       |19.0          |19            |19            |19            |1               |\n",
      "|15       |15.0          |15            |30            |15            |2               |\n",
      "|43       |43.0          |43            |129           |43            |3               |\n",
      "+---------+--------------+--------------+--------------+--------------+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_agg.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "910176cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: integer (nullable = true)\n",
      " |-- avg(artist_id): double (nullable = true)\n",
      " |-- max(artist_id): integer (nullable = true)\n",
      " |-- sum(artist_id): long (nullable = true)\n",
      " |-- min(artist_id): integer (nullable = true)\n",
      " |-- count(artist_id): long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc07d905",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64be1edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|artist_id|count|\n",
      "+---------+-----+\n",
      "|       26|    4|\n",
      "|        1|    7|\n",
      "|       50|    4|\n",
      "|       33|    5|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"artist_id\").count().filter(col(\"count\") > 3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19ee33",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£9Ô∏è‚É£ `sum()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Computes sum.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aaae79d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+\n",
      "|artist_id|sum(artist_id)|\n",
      "+---------+--------------+\n",
      "|       26|           104|\n",
      "|       43|           129|\n",
      "|       50|           200|\n",
      "|       33|           165|\n",
      "|       46|           138|\n",
      "|       36|           108|\n",
      "+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"artist_id\").sum(\"artist_id\").filter(col(\"sum(artist_id)\") > 100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6171c7d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3Ô∏è‚É£0Ô∏è‚É£ `avg()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Average aggregation.\n",
    "\n",
    "### **Interview**\n",
    "\n",
    "> Uses **double precision** internally\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d297a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3Ô∏è‚É£1Ô∏è‚É£ `min()` / `max()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Minimum / maximum value.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bab45b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"dept\").max(\"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe170d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£2Ô∏è‚É£ `countDistinct()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Counts unique values.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9868a06",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "df.select(countDistinct(\"user_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6f186",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Expensive ‚Üí requires shuffle\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£3Ô∏è‚É£ `approx_count_distinct()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Approximate distinct count.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Massive performance gain.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839327a8",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "df.select(approx_count_distinct(\"user_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16055fe1",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Uses **HyperLogLog++**\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£4Ô∏è‚É£ `pivot()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Converts rows ‚Üí columns.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23674be",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"dept\").pivot(\"year\").sum(\"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfa4c11",
   "metadata": {},
   "source": [
    "### **Use Case**\n",
    "\n",
    "* Reports\n",
    "* BI transformations\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£5Ô∏è‚É£ `join()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Combines DataFrames.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda02ab9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df1.join(df2, on=\"id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec85a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£6Ô∏è‚É£ Join Types\n",
    "\n",
    "| Type  | Use             |\n",
    "| ----- | --------------- |\n",
    "| inner | Matching rows   |\n",
    "| left  | All left rows   |\n",
    "| right | All right rows  |\n",
    "| full  | All rows        |\n",
    "| semi  | Exists in right |\n",
    "| anti  | Not exists      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0850cac",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df1.join(df2, \"id\", \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfdb1b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£7Ô∏è‚É£ `broadcast()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Broadcasts small table.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Avoids shuffle.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d712c07",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "df_large.join(broadcast(df_small), \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2c725",
   "metadata": {},
   "source": [
    "### **Interview Gold**\n",
    "\n",
    "> Broadcast if **< 10‚Äì50 MB**\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£8Ô∏è‚É£ `crossJoin()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Cartesian product.\n",
    "\n",
    "### **Danger**\n",
    "\n",
    "‚ùå Extremely expensive.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£9Ô∏è‚É£ `union()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Row-wise union.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0004c9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df1.union(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a46dd83",
   "metadata": {},
   "source": [
    "### **Requirement**\n",
    "\n",
    "> Same schema order\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£0Ô∏è‚É£ `unionByName()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Union by column name.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Schema mismatch safe.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9e675",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df1.unionByName(df2, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59da63",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£1Ô∏è‚É£ `intersect()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Common rows.\n",
    "\n",
    "### **Cost**\n",
    "\n",
    "‚ö†Ô∏è Shuffle required.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£2Ô∏è‚É£ `exceptAll()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Rows in DF1 not in DF2.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£3Ô∏è‚É£ `having` (via filter)\n",
    "\n",
    "### **What**\n",
    "\n",
    "Filter after aggregation.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d221a1",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"dept\").count().filter(\"count > 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f5edf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£4Ô∏è‚É£ `groupingSets()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Multiple groupings.\n",
    "\n",
    "### **Why**\n",
    "\n",
    "Advanced analytics.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£5Ô∏è‚É£ `rollup()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Hierarchical aggregation.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc5515",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.rollup(\"country\", \"state\").sum(\"sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2465aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£6Ô∏è‚É£ `cube()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "All combinations aggregation.\n",
    "\n",
    "### **Interview**\n",
    "\n",
    "> More expensive than `rollup`\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£7Ô∏è‚É£ `repartition()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Changes partition count (shuffle).\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc869752",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.repartition(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048bcb3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£8Ô∏è‚É£ `coalesce()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Reduce partitions (no shuffle).\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40ed87",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.coalesce(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445217b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£9Ô∏è‚É£ `explain()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Execution plan.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f089fd4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e491fc",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Know **Logical vs Physical Plan**\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£0Ô∏è‚É£ `cache()` / `persist()`\n",
    "\n",
    "### **What**\n",
    "\n",
    "Stores DF in memory.\n",
    "\n",
    "### **How**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998bd298",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a0d254",
   "metadata": {},
   "source": [
    "### **Interview**\n",
    "\n",
    "> Use before **multiple actions**\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Interview Coverage (Part 2)\n",
    "\n",
    "‚úî Aggregations\n",
    "‚úî Joins (broadcast vs shuffle)\n",
    "‚úî Set operations\n",
    "‚úî Performance tuning\n",
    "\n",
    "---\n",
    "\n",
    "## üëâ Next:\n",
    "\n",
    "**PART 3 (51‚Äì75):**\n",
    "\n",
    "* Window functions\n",
    "* UDFs\n",
    "* JSON / Date / Array / Map functions\n",
    "* explode, collect_list\n",
    "* SQL functions vs DataFrame API\n",
    "\n",
    "Say **‚ÄúContinue Part 3‚Äù**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
